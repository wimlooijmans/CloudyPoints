{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create manually a paths.csv file in /data that contains on each the absolute path to a dataset: \\\n",
    "DatasetName,PathToDataset\n",
    "\n",
    "The csv is read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_data = {}\n",
    "\n",
    "with open('../data/paths.csv', newline='') as csvfile:\n",
    "    pathsreader = csv.reader(csvfile, delimiter=';')\n",
    "    for row in pathsreader:\n",
    "        paths_to_data[row[0]] = Path(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_cityscapes = paths_to_data[\"Cityscapes\"]\n",
    "path_cityscapes_leftImg8bit = path_cityscapes / 'leftImg8bit_trainvaltest (11GB)' / 'leftImg8bit'\n",
    "path_cityscapes_rightImg8bit = path_cityscapes / 'rightImg8bit_trainvaltest (11GB)' / 'rightImg8bit'\n",
    "path_cityscapes_disparity = path_cityscapes / 'disparity_trainvaltest (3.5GB)' / 'disparity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_new_size(image, max_height):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    # width = image.size[0]\n",
    "    # height = image.size[1]\n",
    "    height, width, channels = image.shape \n",
    "\n",
    "    ratio = max_height / height\n",
    "\n",
    "    new_width = int(ratio * width)\n",
    "    new_height = int(max_height)\n",
    "\n",
    "    return (new_width, new_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_target = path_cityscapes.parent / 'Resized'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def compute_depth from https://github.com/itberrios/CV_projects/blob/main/multitask_depth_seg/data_exploration/cityscapes_dataset_depth_intuition.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_depth(disparity : np.ndarray, \n",
    "                  w : int = 2048, \n",
    "                  h : int = 1024, \n",
    "                  inpaint_radius : int = None, \n",
    "                  baseline : float = 0.209313, \n",
    "                  f : float = 2262.52, \n",
    "                  max_depth : int = 500) -> np.ndarray:\n",
    "    \"\"\" Computes smooth depth map from disparity \n",
    "        Inputs:\n",
    "            disparity - uint16 dispairty image, \n",
    "            w - disparity width, \n",
    "            h - disparity height, \n",
    "            inpaint_radius - inpainting radius, \n",
    "            baseline stereo baseline distance (meters), \n",
    "            f - camera focal length (pixels) \n",
    "                For CityScapes:\n",
    "                    fx = 2262.52 \n",
    "                    fy = 2265.3017905988554 \n",
    "            max_depth - maximum valid depth (meters)\n",
    "        Outputs: \n",
    "            depth - computed depth map\n",
    "        \"\"\"\n",
    "    \n",
    "    \"\"\" NOTE: For training, need to process all input images just like this! \"\"\"\n",
    "    # crop noisy areas and resize\n",
    "    # disparity = cv.resize(disparity[50:int(h*0.8), 100:], (w,h))\n",
    "    disparity = disparity[50:int(h*0.8), 100:]\n",
    "\n",
    "    # inpaint invalid disparity\n",
    "    if inpaint_radius:\n",
    "        disparity = cv.inpaint(disparity, \n",
    "                                np.uint8(255*(disparity <= 1)), \n",
    "                                inpaintRadius=inpaint_radius, \n",
    "                                flags=cv.INPAINT_TELEA)\n",
    "\n",
    "    # blur to reduce noise\n",
    "    disparity = cv.medianBlur(disparity, 5)\n",
    "\n",
    "    # scale to get True Disparity\n",
    "    disparity = disparity.astype(np.float32)\n",
    "    disparity[disparity > 0] = (disparity[disparity > 0] - 1) / 256\n",
    "\n",
    "    # compute depth\n",
    "    depth = baseline * f / (disparity + 0.1)\n",
    "\n",
    "    # clip and return\n",
    "    return np.clip(depth, 0, max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_city_data(set_name, city, path_cityscapes_leftImg8bit, path_cityscapes_rightImg8bit, path_cityscapes_disparity, path_target, max_height):\n",
    "\n",
    "    path_city = path_cityscapes_leftImg8bit / set_name / city\n",
    "    for path_left_image in [x for x in path_city.iterdir()]:\n",
    "        image_name = path_left_image.stem[0:-12]\n",
    "        \n",
    "        path_right_image = path_cityscapes_rightImg8bit / set_name / city / (image_name + \"_rightImg8bit.png\")\n",
    "        path_disparity_image = path_cityscapes_disparity / set_name / city / (image_name + \"_disparity.png\")\n",
    "\n",
    "        left_image = cv.imread(path_left_image, cv.COLOR_BGR2RGB)\n",
    "        # right_image = cv.imread(path_right_image, cv.COLOR_BGR2RGB)\n",
    "        disparity_image = cv.imread(path_disparity_image, cv.IMREAD_UNCHANGED)\n",
    "\n",
    "        depth_image = compute_depth(disparity_image, inpaint_radius=12)\n",
    "        \n",
    "        w = 2048\n",
    "        h = 1024\n",
    "        # left_image_resized = cv.resize(left_image[50:int(h*0.8), 100:], (w,h))\n",
    "        left_image_crop = left_image[50:int(h*0.8), 100:]\n",
    "\n",
    "        # resize\n",
    "        new_size = calculate_new_size(left_image_crop, max_height)\n",
    "        left_image_resized = cv.resize(left_image_crop, new_size)\n",
    "        depth_image_resized = cv.resize(depth_image, new_size)\n",
    "        \n",
    "        # Save left image\n",
    "        cv.imwrite(path_target / 'left_images' / set_name / (image_name + \"_left_image.png\"), left_image_resized)\n",
    "        cv.imwrite(path_target / 'depth' / set_name / (image_name + \"_depth_image.png\"), depth_image_resized)\n",
    "\n",
    "MAX_HEIGHT = 400\n",
    "\n",
    "# prep_city_data('train', 'aachen', path_cityscapes_leftImg8bit, path_cityscapes_rightImg8bit, path_cityscapes_disparity, path_target, MAX_HEIGHT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "train\n",
      "val\n"
     ]
    }
   ],
   "source": [
    "# Resize images and create depth map\n",
    "for set_name in [x.stem for x in path_cityscapes_leftImg8bit.iterdir() if x.is_dir()]:\n",
    "    print(set_name)\n",
    "    path_set = path_cityscapes_leftImg8bit / set_name\n",
    "    for city in [x.stem for x in path_set.iterdir() if x.is_dir()]:            \n",
    "            prep_city_data(set_name,\n",
    "                        city,\n",
    "                        path_cityscapes_leftImg8bit,\n",
    "                        path_cityscapes_rightImg8bit,\n",
    "                        path_cityscapes_disparity,\n",
    "                        path_target,\n",
    "                        MAX_HEIGHT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DepthEstimationKeras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
